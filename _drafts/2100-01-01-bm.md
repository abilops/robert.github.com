---
layout: post
title: "Bm"
tags: [Security, Privacy]
og_image: https://robertheaton.com/TODO
---
You are worried about your good buddy and co-CEO, Steve Steveington. Business has been bad at Steveslist, the online marketplace that you co-founded together where people can buy and sell things and where no one asks too many questions. The Covid-19 pandemic has been kind to much of the tech industry, but not to your particular piece of it. Your board of directors blame "comatose, monkey-brained leadership". You blame macro-economic factors outside your control and lazy employees.

Either way, you've been trying as best you can to keep the company afloat, cooking your books browner than ever and turning an even blinder eye to plainly illegal transactions. You aren't worried for yourself; you're worried for your team of 190 assorted interns, volunteers, and unpaid trial workers. They all rely on this job, if not for income, then for valuable work experience that might one day help them break into the industry.

But you're scared that the Stevenator, your co-CEO, is getting cold feet. You keep telling him that the only way out of this tempest is through it, but he doesn't think that this metaphor really applies here and he doesn't see how a spiral further into fraud and flimflam could ever lead out of another side. This makes you even more worried - Steve is always the one pushing for more spiralling. Something must be afoot.

Your office in the 19th Century Literature section of the San Francisco Public Library is only a mile away from the headquarters of the San Francisco FBI. Could Steve be ratting you out? He knows just as well as you the kinds of questionable commerce that the Steveslist platform aids and abets, and how the federal government would feel about its co-CEO's if they knew about it. When he says he's nipping out to clear his head, is he actually nipping out to clear his conscience? You would follow him to find out, but he always goes out for these constitutionals when you're in the middle of an important call with a prospective unpaid trial worker. You're hiring for a new CFO to take the fall for your rotisseried tax returns and you're down to a shortlist of three.

Fortunately the Stevester is an avid user of Bumble, the popular online dating app. He was previously a Tinder user, but after a run of no luck he switched to Bumble, citing as reason for his realignment the fact that Tinder is "full of \*\*\*\*\*\* and \*\*\*\*\*\*\*\* \*\*\*\*\*". You don't see how he would know this first-hand, since you know when he last actually went on a date and who was president at the time, but you don't say anything. Anyway, you think you may be able to use Steve's Bumble account to find out where he is sneaking off to.

<img src="/images/bumble-phone.png" />

Here's the plan. Like most online dating apps, Bumble tells its users how far away they are from each other. This enables a user to make an informed decision about whether a potential paramour looks like they're worth a 5 mile scooter ride on a bleak Wednesday evening when there's still so much YouTube that they haven't watched. It's practical and provocative to know roughly how close a hypothetical honey is, but it's very important that Bumble doesn't reveal a user's exact location. This could allow an attacker to deduce where the user lives, where they are right now, and whether or not they are an FBI informant.

This is surprisingly easy to foul up, however. You may already be familiar with the history of location-revealing vulnerabilities from [a previous blog post in which you tried to exploit Tinder's user location features](https://robertheaton.com/2018/07/09/how-tinder-keeps-your-location-a-bit-private/), in a Steve Steveington-centric scenario lazily similar to this one. But even if you've already read that post then you should still stick with this one - the recap section is short and after that things get interesting.

As one of the trailblazers of location-based online dating, Tinder was inevitably also one of the trailblazers of location-based security vulnerabilities. Over the years they've accidentally allowed an attacker to find the exact location of their users in several different ways. The first vulnerability was prosaic. Until 2014, the Tinder servers sent a user's Tinder app the exact co-ordinates of a potential match, then had the app calculate the distance between the user and the match. The app didn't display the other user's exact co-ordinates, but an attacker or interested creep could intercept their own network traffic on its way from the Tinder server to their phone and read their target's exact co-ordinates out of it.

```javascript
{
  "user_id": 1234567890,
  "location": {
    "latitude": 37.774904,
    "longitude": 122.419422
  }
  // ...etc...
}
```

To mitigate this attack, Tinder switched to calculating the distance between users on their server, rather than on users' phones. Instead of sending a match's exact location to a user's phone, they sent only pre-calculated distances. This meant that the Tinder app never saw a potential match's exact co-ordinates, and so neither could an attacker. However, even though the app only displayed distances rounded to the nearest mile ("8 miles", "3 miles"), Tinder sent these distances to the app with 15 decimal places of precision and had the app round them before displaying them. This unnecessary precision allowed security researchers to use a technique called *trilateration* to re-derive a victim's almost-exact location.

Here's how trilateration works. Tinder knows a user's location because their app periodically sends it to them. However, it is straightforward to spoof fake location updates that make Tinder think you're at an arbitrary location of your choosing. The researchersÂ spoofed location updates to Tinder, moving their attacker user around their victim's city. From each spoofed location, they asked Tinder how far away their victim was. Seeing nothing amiss, Tinder returned the answer, to 15 decimal places of precision. The researchers repeated this process 3 times, and then drew 3 circles on a map, with centres equal to the spoofed locations and radii equal to the reported distances to the user. The point at which all 3 circles intersected gave the exact location of the victim.

<img src="/images/bumble-trilateration.png" />

Tinder fixed this vulnerability by both calculating and rounding the distances between users on their servers, and only ever sending the app these fully-rounded values. You've read on the internet that this is what Bumble does too, perhaps learning from Tinder's mistakes. Rounded distances can still be used to do approximate trilateration, but only to within a mile-by-mile square or so. This isn't good enough for you, since it won't tell you whether the Stevester is at FBI HQ or at the MacDonalds half a mile away. In order to locate Steve with the precision you need, you're going to need to find a new vulnerability.

<img src="/images/bumble-trilateration-approx.png" />

You're going to need help.

----

You can always rely on your other good buddy, Kate Kateberry, to get you out of a jam. You still haven't paid her for all the systems design help she gave you last year[LINK], but fortunately she too has not a few enemies of her own who she needs to keep tabs on. She could also make good use of a vulnerability in Bumble that revealed a user's exact location. After a brief phone call she hurries over to your offices in the San Francisco Public Library to start looking for one.

When she arrives she hums and haws and has an idea.

"Our problem", she says, "is that Bumble rounds the distance between two users, and sends only this approximate distance to the Bumble app. As you know, this means that we can't do trilateration with any useful precision. However, the details of how and in what order Bumble calculate approximate distances are very important, and contain opportunities for them to make mistakes that we can exploit."

"One sensible-seeming approach would be for Bumble to calculate the exact distance between two users and then round this distance to the nearest mile. The code to do this might look something like this:

```python
def calculate_approximate_distance(user1_location, user2_location):
    # Get the exact distance
    exact_distance = calculate_exact_distance(user1_location, user2_location)
    # Round it
    rounded_distance = math.round(exact_distance)

    # Return the rounded distance
    return rounded_distance
```

"Sensible-seeming yes, but also dangerously insecure. If an attacker (i.e. us) can find the point at which the reported distance to a user flips from, say, 7 miles to 8 miles, they can infer that this is the point at which their victim is exactly 7.5 miles away from them. 7.49999 miles rounds down to 7 miles, 7.50000 rounds up to 8. The attacker can find these flipping points by spoofing a location request that puts them in roughly the vicinity of their victim, then slowly shuffling their position in a constant direction, at each point asking Bumble how far away their victim is. When the reported distance changes from (say) 7 to 8 miles, they've found a flipping point. If the attacker can find 3 different flipping points then they've once again got 3 exact distances to their victim and can perform precise trilateration, exactly as the researchers attacking Tinder did.

How do we know if this is what Bumble does? you ask. "We try out an attack and see if it works", replies Kate.

----

In order to test this hypotehtical attack you and Kate are going to need to write an automated script that sends a carefully crafted sequence of requests to the Bumble servers, leaping your user around the city and repeatedly asking for the distance to your victim. To do this you'll need to work out:

* How the Bumble app communicates with the server
* How the Bumble API works
* How to send API requests that change your location
* How to send API requests that tell you how far away another user is

You can't download the Bumble smartphone app because you've lost your phone. You're pretty sure it's in your apartment somewhere but you can't find it. You aren't sure if you're allowed to claim on your insurance in this kind of situation. Fortunately, Bumble have a website that you can use on your laptop.

You'll need some Bumble accounts. You used to have one but you got banned for being a bot, even though you weren't, you were just in a bit of a funk and didn't have much original material. Nonetheless, for testing this attack you'll need two accounts: one to be the attacker and one to be the victim. You'll place the victim account in a known location, and use the attacker's account to re-locate them. Once you've perfected the attack in the lab you'll trick Steve into matching with one of your accounts, and launch the attack against him.

You sign up for your first Bumble account. It asks you for a profile picture. To preserve your privacy you upload a picture of the ceiling. Bumble rejects it for "not passing our photo guidelines." They must be performing facial recognition. You upload a stock photo of a man in a nice shirt pointing at a whiteboard.

<img src="/images/bumble-man-unphotoshopped.png" />

Bumble rejects it again. They must be comparing the photo against a database of stock photos. You flip the photo and scribble on the background with a paintbrush tool. Bumble accepts the photo! However, they next ask you to submit a new selfie of yourself putting your right hand on your head, to prove that the picture really is of you. You don't know how to contact the man in the stock photo and you're not sure that he would send you a selfie. You do your best, but Bumble rejects your effort. There's no option to change your initially submitted profile photo until you've passed this verification so you abandon this account and start again.

<img src="/images/bumble-man-photoshopped.png" />

You don't want to compromise your privacy by submitting real photos of yourself, so you take a profile picture of Jenna the intern and then another picture of her with her right hand on her head. She is confused but she knows who pays her salary, or at least who might one day pay her salary if the next six months go well and a suitable full-time position is available. You take the same set of photos of Wilson in...marketing? Finance? Who cares. You successfully create two accounts, and now you're ready to start swiping.

You want to make your accounts match with each other. This might not be strictly necessary, but it should be straightforward to do and should presumably give your accounts the best possible access to each other's information. You restrict Jenna and Wilson's match filter to "within 1 mile" and start swiping. Before too long your Jenna account is shown your Wilson account, so you swipe right to indicate her interest. However, your Wilson account keeps swiping left without ever seeing Jenna, until eventually he is told that he has seen all the potential matches in his area. Strange. You see a notification telling Wilson that someone has already "liked" him. Sounds promising. You click on it. Bumble demands $1.99 in order to show you your not-so-mysterious admirer.

You preferred it when these dating apps were in their hyper-growth phase and your trysts were paid for by venture capitalists. You reluctantly reach for the company credit card but Kate hits it out of your hand. "We don't need to pay for this. I bet we can bypass this paywall. Let's pause trying to get Jenna and Wilson to match and start investigating how the app works." Never one to pass up the opportunity to stiff a few bucks, you happily agree.

In order to figure out how the app works, you need to work out how to send API requests to the Bumble servers. Their API isn't publicly documented because it isn't intended to be used for automation and Bumble doesn't want people like you doing things like what you're doing.Â  "We'll use a tool called Burp Suite," Kate says. "It's an HTTP proxy, which means we can use it to intercept HTTP requests going from the Bumble web app to the Bumble servers. By studying the requests and responses we can work out how to replay and edit them. This will allow us to make our own, customized HTTP requests from a script, without needing to go through the Bumble app or website."

[PIC - proxy] WHIM

Kate sets up Burp Suite, and shows you the HTTP requests that your laptop is sending to the Bumble servers. She swipes yes on a rando. "See, this is the HTTP request that Bumble sends when you swipe right on someone.

```http
POST /mwebapi.phtml?SERVER_ENCOUNTERS_VOTE HTTP/1.1
Host: eu1.bumble.com
Cookie: CENSORED
Content-Length: 286
Sec-Ch-Ua: " Not;A Brand";v="99", "Google Chrome";v=91", "Chromium";v="91"
X-Use-Session-Cookie: 1
Sec-Ch-Ua-Mobile: ?0
User-Agent: Mozilla/5.0 (Macintosh; Intel Max OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0
X-Pingback: 81df75f32cf12a5272b798ed01345c1c
Content-Type: application/json
Accept: */*
Origin: https://us1.bumble.com
Sec-Fetch-Size: same-site
Sec-Fetch-Mode: cors
Sec-Fetch-Dest: empty
Referer: https://us1.bumble.com/
Accept-Encoding: gzip, deflate
Accept-Language: en-GB,en
Dnt: 1
Sec-Gpc: 1
Connection: close

{
  "$gpb": "badoo.bma.BadooMessage",
  "body": [
    {
      "message_type": 80,
      "server_encounters_vote": {
        "person_id": "CENSORED",
        "vote": 3,
        "vote_source": 1,
        "game_mode":0
      }
    }
  ],
  "message_id": 71,
  "message_type": 80,
  "version": 1,
  "is_background": false
}
```

"There's the user ID of the swipee, in the `person_id` field inside the `body` field. If we can figure out the user ID of Jenna's account, we can insert it into this 'swipe yes' request from our Wilson account. If Bumble doesn't check that the user you swiped is currently in your feed then they'll probably accept the swipe and match Wilson with Jenna." How can we work out Jenna's user ID? you ask.

"I'm sure we could find it by inspecting HTTP requests sent by our Jenna account" says Kate, "but I have a more interesting idea." Kate finds the HTTP request and response that loads Wilson's list of pre-yessed accounts (which Bumble calls his "Beeline"). "Look, this request returns a list of blurred images to display on the Beeline page. But alongside each image it also shows the user ID that that image belongs to! That second picture is of Jenna, so the user ID alongside it must be Jenna's." Wouldn't this allow anyone to swipe yes on all the people who have swiped yes on them, without paying Bumble $1.99? you ask. "Yes," says Kate. "Anyway, let's insert Jenna's ID into a swipe-yes request and see what happens."

## Forging a signature [TODO - more titles?]

What happens is that Bumble returns a "Server Error". "That's strange," says Kate. "I wonder what it didn't like about our edited request." After some experimentation, Kate realises that if you edit anything about the HTTP body of a request, even just adding an innocuous extra space at the end of it, then the edited request will fail. "That suggests to me that the request contains something called a *signature*," says Kate. You ask what that means.

"A signature is a string of random-looking characters that is generated from a piece of text. There are many different ways of generating signatures, but for a given signing process, the same text will always produce the same signature.

<img src="/images/bumble-sigs-general.png" />

"This means that a signature can be used to verify that a piece of text hasn't been tampered with. The verifier can re-generate a text's signature, and if it matches then the text hasn't been tampered with. If the signature doesn't match, it has been tampered with. If the HTTP requests that we're sending to Bumble contain a signature then this would explain why we're seeing an error message whenever we change anything about the request's body, even if the change doesn't change the meaning of the request at all. The JavaScript running on the Bumble website must generate the signature and attach it to the HTTP request before sending it. When the Bumble server receives the request, it verifies the signature and accept the request if it is valid; and rejects it if it isn't. This makes it very, very slightly harder for sneakertons like us to mess with their system.

<img src="/images/bumble-sigs-http.png" />

"However", continues Kate, "even without knowing anything about how these signatures are produced, I can say for certain that they don't provide any actual security. The problem is that the signatures are generated by JavaScript running on the Bumble website, which executes on our computer. This means that we have access to the JavaScript code that generates the signatures, including any "secret" keys that are used. This means that we can read the code, work out what it's doing, and perform the same process on our own requests in order to generate our own signatures for our own edited requests. The Bumble servers will have no idea that the signatures were generated by us, rather than the Bumble website.

"Let's try and find the signatures in these requests. We're looking for a random-looking string, maybe 30 characters or so long. It could technically be anywhere in the request - path, headers, body - but I would guess that it's in a header." How about this? you say, pointing to an HTTP header called `X-Pingback` with a value of `81df75f32cf12a5272b798ed01345c1c`.

```http
POST /mwebapi.phtml?SERVER_ENCOUNTERS_VOTE HTTP/1.1
...
User-Agent: Mozilla/5.0 (Macintosh; Intel Max OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0
X-Pingback: 81df75f32cf12a5272b798ed01345c1c
Content-Type: application/json
...
```

"Perfect," says Kate, "that's an odd name for the header, but the value sure looks like a signature." This sounds like progress, you say. But how can we find out how to generate our own signatures for our edited requests?

"We can start with a few educated guesses," says Kate. "I suspect that the programmers who built Bumble know that these signatures don't actually secure anything. I suspect that they only use them in order to dissuade unmotivated tinkerers and create a small speedbump for motivated ones like us. They might therefore just be using a simple *hash function*, like MD5 or SHA256. No one would ever use a bare hash function to generate real, cryptographically secure signatures, but it's perfectly reasonable to use them to generate small inconveniences." Kate copies the HTTP body of a request into a file and runs it through a few such simple functions. None of them match the signature in the request. "No problem," says Kate, "we'll just have to read the JavaScript."

Is this reverse-engineering? you ask. "It's not as fancy as that," says Kate. "'Reverse-engineering' implies that we're probing the system from afar, and using the inputs and outputs that we observe to infer what's going on inside it. But here all we have to do is read the code." Can I still write reverse-engineering on my CV? you ask. But Kate is busy.

Kate is right that all you have to do is read the code, but reading code isn't always easy. As is standard practice, Bumble have squashed all their JavaScript into one highly-condensed or *minified* file. They've primarily done this in order to reduce the amount of data that they have to send to users of their website, but minification also has the side-effect of making it trickier for an interested observer to understand the code. The minifier has removed all comments; changed all variables from descriptive names like `signBody` to inscrutable single-character names like `f` and `R`; and concatenated the code onto 39 lines, each thousands of characters long.

<img src="/images/bumble-js-minified.png" />

You suggest giving up and just asking Steve as a friend if he's an FBI informant. Kate firmly and impolitely forbids this. "We don't need to fully understand the code in order to work out what it's doing." She downloads Bumble's single, giant JavaScript file onto her computer. She runs it through a un-minifying tool to make it easier to read. This can't bring back the original variable names or comments, but it does reformat the code sensibly on multiple lines which is still a big help. The expanded version weighs in at a little over 51,000 lines of code.

<img src="/images/bumble-js-unminified.png" />

Next she searches for the string `X-Pingback`. Since this is a string, not a variable name, it shouldn't have been affected by the minification and un-minification process. She finds the string on line 36,880 and starts tracing function calls to see how it is generated.

TODO IMG - of X-Pingback[

You start to believe that this might work. A few minutes later she announces two discoveries.

"First", she says, "I've found the function that generates the signature, on line 36,657."

<img src="/images/bumble-md5.png" />

Oh excellent,Â  you say, so we just have to re-write that function in our Python script and we're good? "No, dumb dumb," says Kate. The function she has found contains lots of long, random-seeming, hard-coded numbers. She pastes `1732584193`, the first of these numbers, into Google. It returns pages of results for implementations of a widely-used hash function called MD5. "This function is just MD5 written out in JavaScript," she says, "we can just use Python's built-in MD5 implementation in the `crypto` module."

<img src="/images/bumble-md5-google.png" />

But we already tried MD5 and it didn't work, you protest. "True," says Kate, "which brings me to my second discovery. Before passing a request body into MD5 and signing in,Â  Bumble prefixes it with the string `whitetelevisionbulbelectionroofhorseflying`, and then signs the combination of the key and string.

<img src="/images/bumble-secret-key.png" />

This is somewhat similar to how real-world cryptographic signing algorithms like HMAC (Hash-based Message Authentication Code) work. When generating an HMAC, you combine the text that you want to sign with a secret key, then pass it through a deterministic function like MD5. A verifier who knows the secret key can repeat this process to verify that the signature is valid, but an attacker can't generate new signatures because they don't know the secret key. However, this doesn't work for Bumble because their secret key necessarily has to be hard-coded in their JavaScript, and we know what it is. This means that we can generate as many valid new signatures for our own edited requests as we need by adding it to our request bodies and passing the result through MD5."

Kate writes a Python script that builds and sends HTTP requests to the Bumble API. It signs these requests in the `X-Pingback` header using the "secret" key `whitetelevisionbulbelectionroofhorseflying` and the MD5 algorithm. In order to allow her script to act as your Jenna user, Kate copies the Jenna user's cookies from her browser was into her script and adds them into her requests. Now she is able to send a signed, authenticated, customized "match" request to Bumble that matches Wilson with Jenna. Bumble accepts and processes the request, and congratulates her on her new match. You do not have to give Bumble $1.99.

---

Any questions so far? asks Kate. You don't want to sound stupid so you say no.

---

Now that you know how to send arbitrary requests to the Bumble API yourselves, without going through the app or website, you can start testing out a trilateration attack. Kate spoofs an API request to put Wilson in the middle of the Golden Gate Bridge. It's Jenna's task to re-locate him.

Kate starts by putting Jenna in a random location in San Francisco. She then shuffles her south, 0.01 of a degree of latitude each time. With each shuffle she asks Bumble how far away Wilson is. When this flips from 4 to 5 miles, Kate backs Jenna up one step and shuffles south in smaller increments of 0.001 degrees until the distance flips from 4 to 5 again. This backtracking improves the precision of the measured point at which the distance flips.

After some trial and error, Kate realizes that Bumble don't round their distances like most people were taught at school. When most people think of "rounding", they think of a process where the cutoff is `.5`. 3.4999 rounds down to 3; 3.5000 rounds up to 4. However, Bumble *floors* distances, which means that everything is always rounded down. 3.0001, 3.4999, and 3.9999 all round down to 3; 4.0001 rounds down to 4. This discovery doesn't break the attack - it just means you have to edit your script to note that the point at which the distance flips from 3 miles to 4 miles is the point at which the victim is exactly 4.0 miles away, not 3.5 miles.

Kate writes a Python script to repeat this process 3 times, starting at 3 arbitrary locations. Once it has found 3 flipping points, her script draws 3 circles, each centred on a flipping point and with a radius equal to the higher of the two distances either side of the flip. The script takes a long time to develop because if you make too many requests or move yourself too far too often then Bumble *rate-limits* your requests and stops accepting position updates for a while. A stray minus sign temporarily puts Jenna in the middle of the Chinese province of Shandong, but after a brief timeout Bumble allows her to come back.

When the script eventually runs to completion you are both very pleased with what you see.

---

You and Kate have a fun night together catfishing local strangers. You set Wilson and Jenna's profiles to be interested in matches within 1 mile of your current location, and then spend a wholesome evening matching with people, trilaterating them to find out where they live, and knocking on their door while sending them weird Bumble messages. Sometimes you get the wrong house and the prank (or is it by this point a crime?) doesn't really land, but you still have a good time.

The next day you are ready to execute your attack on the Steveinator himself. In order to target him you'll need to find out his user ID, and the easiest way to do this is to match with him. Kate wonders if you need to make a new Bumble profile, since Steve will surely recognize Wilson and Jenna. You tell her that Steve turbo-swipes "Yes" on every person who appears in his feed in order to maximize his reach, which you think used to work back on 2012 Tinder but by now probably just makes Bumble's algorithms think he's desperate. He's also a self-absorbed narcissist who doesn't pay any attention to anyone other than himself, so the chances of him recognizing anyone are very low.

You therefore have Jenna's account swipe yes on Steve and then wait anxiously for a ping. It comes within the hour, during one of Steve's trademark long toilet breaks. It's a match.

You pretend to get on a call with a CFO candidate. Steve slips out of the building. You call Kate over and you execute the trilateration attack on Steve. You can't believe what your script spits out.

Three red circles that meet at the J Edgar Hoover Building, San Francisco. FBI Headquarters.

---

You grab a fork and pledge to kill Steve. Kate, who is trained in conflict resolution, talks you down by suggesting that you eat ten sushi rolls first, and then if you still want to kill him then that's your decision and she will happily give you back your fork. With three rolls remaining Steve sidles back in. You beg Kate to return your fork; she declines since you haven't finished your sushi. She tells you to go and talk to your co-CEO. You drag him into a conference room and start screaming. After twenty minutes you pause and let Steve have his say.

It's not what you think, he protests. I've been trying to get the company back into the black by playing in the FBI poker game. Unfortunately it has not been going well, my goodness me. I might need to turn state's evidence to get out of this new jam.

You remind Steve that you were three sushi rolls away from forking him to death.

Or I suppose we could do some A/B testing and try to improve our sales funnel conversion, he suggests.

You agree that that would be a good idea. You put an arm around him and give him what you hope is a friendly yet highly menacing squeeze. Come on friend, you say, let's get back to work.

---

## Epilogue

Your adventure over without profit, you realize that you are still in possession of a serious vulnerability in an app used by millions of people. You try to sell the information on the dark web, but you can't work out how. You try to sell it on Steveslist but you don't get any messages, which given your active user statistics is perhaps not surprising. With literally every other option exhausted you do the decent thing and report it to the Bumble security team. They reply quickly and within 24 hours have deployed what looks like a fix. They give you a $2,000 bounty, which due to to a tragic misclick you accidentally donate to the Against Malaria Foundation.

You recommend a fix to Bumble. You suggest that when calculating the distance between two users, they should first round the users' locations to the nearest 0.1 degree or so of longitude and latitude. They should then calculate the distance between these two rounded locations, round the result to the nearest mile, and display this rounded value in the app.

<img src="/images/bumble-location-rounding.png" />

By rounding users' locations before calculating the distance between them, Bumble would fix this vulnerability and also give themselves good guarantees that they won't leak locations in the future either. There would be no way that a future vulnerability could expose a user's exact location via trilateration, since the distance calculations wouldn't even have access to it. If Bumble wanted to make these guarantees even stronger then they could have their app only ever send back a user's approximate location. You can't accidentally expose information that you don't collect. However, you suspect that there are commercial reasons why they would rather not do this.

Bumble might have used your suggestion in their fix - you aren't actually sure. The reason you aren't sure is that they introduced randomness into the approximate distances that they return to users. Previously, given two users in the same locations, Bumble would always deterministically return the same rounded distance between them. However, now they return slightly randomized values in a small range. If the true distance between two users is 3 miles then they'll sometimes return "3 miles", but also sometimes "2 miles" and/or "4 miles". This seems like a good idea on the surface, but as a defence against a trilateration attack you believe it's actually almost useless.

This is because if an attacker asks Bumble for the distance between them and a victim enough times then they will be able to build a probability distribution of the responses. This probability distribution must be based somehow on the real distance between the users, otherwise the distance-to-user feature would be nonsense. This means that if the attacker can work out how the randomness is added (for example, maybe 50% of the time it returns the real rounded distance, 25% 1 mile less, 25% 1 mile more), they can use the probability distribution to work out the real rounded distance. If Bumble aren't also applying a more robust defence, such as location-rounding, the attacker will be able to use these inferred rounded distances to perform trilateration, as before. It will just take a bit longer.

<img src="/images/bumble-randomness.png" />

If Bumble are also performing a defence like location-rounding then the randomness doesn't technically hurt. If an attacker is able to work out how randomness is added and infer the real location-rounded distance to a user then this is fine because location-rounded distances are safe to expose. Randomness does add an extra layer of confusion, and requires an attacker to send more API requests in order to execute an attack. However, in your opinion you don't think it's worth the bother. It complicates the system, making it harder to maintain and easier to introduce a vulnerability into in the future. It also gives a false sense of security - you can imagine someone in the future updating the location-calculating code and thinking "oh I see that the randomness makes this secure, no need to take too much care here."

On the other hand, you haven't yet been able to work out how randomness is applied to the returned values, so maybe obfuscation does have some value.

---

It's late. You thank Kate for her help; you've learned a thing or two. You start making flashcards out of your notes on proxies and signatures, or at least you pretend to, since you didn't actually take any notes. You start explaining the benefits of flashcards and spaced repetition to Kate. Oh my god I do not care, she says.

Since you've lost your phone you ask Kate if she'll call you an Uber. She declines, pointing out that you always pull this crap and never pay her back. You don't know how public transport works in this city so you begin the lonely trudge home to the Outer Richmond.
